{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1h50dh4xQXTMKTLriV-jwXCIu0GEppGjO","authorship_tag":"ABX9TyP6u2FwIyz3O/x3BGVyh0fT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","\n","# Belgeler klasörünü oluştur (varsa sorun olmaz)\n","os.makedirs(\"/content/drive/MyDrive/Belgeler\", exist_ok=True)\n","\n","# TXT dosyasının yolu\n","txt_path = \"/content/drive/MyDrive/Belgeler/ai_article.txt\"\n","\n","# İçerik (örnek İngilizce metin)\n","english_text = \"\"\"Artificial intelligence (AI) is rapidly transforming industries worldwide.\n","From healthcare to finance and transportation, AI systems are being used to analyze massive datasets,\n","recognize complex patterns, and assist humans in making critical decisions.\n","Breakthroughs in deep learning and natural language processing have led to impressive advances\n","in image recognition, speech synthesis, and text generation.\n","\n","However, building and deploying AI responsibly requires more than high accuracy.\n","Modern AI faces three major challenges: explainability, efficiency, and security.\n","Explainability ensures that models are transparent and that their decisions can be trusted by doctors,\n","policymakers, and end users. Efficiency focuses on reducing computational costs through model compression,\n","pruning, and quantization so that AI can run effectively even on limited hardware.\n","Security involves defending models against adversarial attacks, data poisoning, and distribution shifts\n","that could degrade performance in real-world environments.\n","\n","To address these challenges, researchers and engineers are developing new techniques such as interpretable\n","machine learning, knowledge distillation, and adversarial training.\n","These methods not only improve technical performance but also enhance the reliability and fairness of AI applications.\n","Ultimately, responsible AI will combine cutting-edge innovation with practical safeguards,\n","enabling technology to deliver long-term value for society.\"\"\"\n","\n","# Dosyaya yaz\n","with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n","    f.write(english_text)\n","\n","print(\"TXT dosyası başarıyla oluşturuldu:\", txt_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUhqgnWsJuPn","executionInfo":{"status":"ok","timestamp":1757952815378,"user_tz":-180,"elapsed":51,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}},"outputId":"d170dff4-175d-4dd2-e52e-2b7615cc2ee4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["TXT dosyası başarıyla oluşturuldu: /content/drive/MyDrive/Belgeler/ai_article.txt\n"]}]},{"cell_type":"code","source":["!pip -q install -U requests==2.32.4\n","!pip -q install transformers==4.44.2 accelerate==0.34.2 nltk==3.9.1\n"],"metadata":{"id":"MI2fdca9Y0PE","executionInfo":{"status":"ok","timestamp":1757956768789,"user_tz":-180,"elapsed":6017,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["import re, heapq, nltk, torch\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n","\n","# NLTK veri setleri\n","nltk.download('punkt', quiet=True)\n","nltk.download('punkt_tab', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","set_seed(42)\n","\n","# >>> MODEL: gpt2-medium (345M parametre)\n","MODEL_NAME = \"gpt2-medium\"\n","tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n","tok.pad_token = tok.eos_token\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    torch_dtype=torch.float16 if torch.cuda.is_available() else None\n",").to(DEVICE)\n","model.eval()\n","\n","EN_STOP = set(stopwords.words(\"english\"))\n","\n","# -------- Girdi temizliği --------\n","def sanitize_email_forums(text: str) -> str:\n","    t = re.sub(r'^(From|To|Cc|Subject|Date|Reply-To):.*$', ' ', text, flags=re.MULTILINE|re.IGNORECASE)\n","    t = re.sub(r'-{6,}\\s*next part\\s*-{6,}.*$', ' ', t, flags=re.IGNORECASE|re.MULTILINE|re.DOTALL)\n","    t = re.sub(r'An HTML attachment was scrubbed.*$', ' ', t, flags=re.IGNORECASE|re.MULTILINE)\n","    t = re.sub(r'https?://\\S+|www\\.\\S+', ' ', t)\n","    t = re.sub(r'<[^>\\n]+>', ' ', t)\n","    t = re.sub(r'\\S+@\\S+', ' ', t)\n","    t = re.sub(r'\\b[0-9a-f]{16,}\\b', ' ', t, flags=re.IGNORECASE)\n","    t = re.sub(r'\\s+', ' ', t).strip()\n","    return t\n","\n","# -------- Ekstraktif özet (önemli cümle seçimi) --------\n","def clean_text(t: str) -> str:\n","    t = re.sub(r'\\u200b', '', t)\n","    t = re.sub(r'\\s+', ' ', t).strip()\n","    return t\n","\n","def extractive_summary(text: str, max_sents: int = 8) -> str:\n","    text = clean_text(text)\n","    sents = sent_tokenize(text, language=\"english\")\n","    if len(sents) <= max_sents:\n","        return text\n","\n","    words = word_tokenize(text.lower(), language=\"english\")\n","    words = [w for w in words if w.isalpha() and w not in EN_STOP]\n","\n","    freq = {}\n","    for w in words:\n","        freq[w] = freq.get(w, 0) + 1\n","    maxf = max(freq.values()) if freq else 1\n","    for w in freq:\n","        freq[w] = freq[w] / maxf\n","\n","    scored = []\n","    for i, s in enumerate(sents):\n","        sw = word_tokenize(s.lower(), language=\"english\")\n","        sc = sum(freq.get(w, 0) for w in sw)\n","        scored.append((sc, i, s))\n","\n","    top = heapq.nlargest(max_sents, scored)\n","    top_sorted = [s for _, _, s in sorted(top, key=lambda x: x[1])]\n","    return \" \".join(top_sorted)\n","\n","# -------- Bullet üretimi (ekstraktif, garanti) --------\n","def extractive_bullets(text: str, n: int = 4) -> list[str]:\n","    sents = sent_tokenize(text, language=\"english\")\n","    return [s.strip() for s in sents[:n]]\n","\n","# -------- Çıktı temizliği --------\n","def strip_links_emails(text: str) -> str:\n","    t = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n","    t = re.sub(r'<[^>\\n]+>', '', t)\n","    t = re.sub(r'\\S+@\\S+', '', t)\n","    t = re.sub(r'[ \\t]+\\n', '\\n', t)\n","    return t.strip()\n","\n","# -------- GPT-2 Medium ile paragraf özet (strict prompt) --------\n","def gpt2_paragraph(text: str,\n","                   max_new_tokens: int = 160) -> str:\n","    prompt = (\n","        \"Write ONE short paragraph (3-5 sentences) summarizing the text below. \"\n","        \"ONLY use facts from the text. Do not add new topics, names, or predictions. \"\n","        \"Keep it factual, concise, and neutral.\\n\\n\"\n","        f\"Text:\\n{text}\\n\\nSummary:\"\n","    )\n","\n","    inputs = tok(prompt, return_tensors=\"pt\").to(DEVICE)\n","    with torch.no_grad():\n","        out = model.generate(\n","            **inputs,\n","            max_new_tokens=max_new_tokens,\n","            do_sample=False,              # deterministik mod\n","            no_repeat_ngram_size=3,\n","            repetition_penalty=1.12,\n","            pad_token_id=tok.eos_token_id,\n","            eos_token_id=tok.eos_token_id,\n","            return_dict_in_generate=True\n","        )\n","\n","    # Sadece üretilen kısmı al (promptu atla)\n","    gen_ids = out.sequences[0][inputs[\"input_ids\"].shape[1]:]\n","    para = tok.decode(gen_ids, skip_special_tokens=True).strip()\n","    para = strip_links_emails(para)\n","\n","    # Fallback: paragraf çok kısa veya boşsa ekstraktif cümlelerden 3-4 tane al\n","    sents = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', para) if s.strip()]\n","    if len(para) < 40 or len(sents) < 2:\n","        base = extractive_summary(sanitize_email_forums(text), max_sents=6)\n","        base_sents = sent_tokenize(base, language=\"english\")[:4]\n","        para = \" \".join(base_sents)\n","        para = strip_links_emails(para)\n","\n","    return para\n","\n","\n","    # Sadece üretilen kısmı al (promptu atla)\n","    gen_ids = out.sequences[0][inputs[\"input_ids\"].shape[1]:]\n","    para = tok.decode(gen_ids, skip_special_tokens=True).strip()\n","    para = strip_links_emails(para)\n","\n","    # Basit kalite kontrol + Fallback\n","    #  - boşsa veya tek cümleyse, ekstraktif cümlelerden paragraf kur\n","    sents = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', para) if s.strip()]\n","    if len(para) < 40 or len(sents) < 2:\n","        # Ekstraktiften 3-4 cümle ile güvenli paragraf\n","        base = extractive_summary(sanitize_email_forums(text), max_sents=6)\n","        base_sents = sent_tokenize(base, language=\"english\")[:4]\n","        para = \" \".join(base_sents)\n","        para = strip_links_emails(para)\n","\n","    return para\n","\n","\n","\n","# -------- Hybrid summarizer --------\n","def summarize_hybrid(text: str, bullets: int = 4, max_sents: int = 8) -> str:\n","    cleaned = sanitize_email_forums(text)\n","    base = extractive_summary(cleaned, max_sents=max_sents)\n","    blts = extractive_bullets(base, n=bullets)\n","    para = gpt2_paragraph(base)\n","    bullets_block = \"\\n- \".join(blts) if blts else \"\"\n","    merged = f\"BULLETS:\\n- {bullets_block}\\n\\nPARAGRAPH:\\n{para}\"\n","    return strip_links_emails(merged)\n"],"metadata":{"id":"_1LRyeTXY3CP","executionInfo":{"status":"ok","timestamp":1757957370660,"user_tz":-180,"elapsed":2343,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["txt_path = \"/content/drive/MyDrive/Belgeler/ai_article.txt\"  # <-- kendi yolunu yaz\n","with open(txt_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n","    text_data = f.read()\n","print(\"Characters:\", len(text_data))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wACwTSDOY-5Z","executionInfo":{"status":"ok","timestamp":1757957372392,"user_tz":-180,"elapsed":19,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}},"outputId":"6199f2be-b485-41d8-9707-883783b3dc25"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Characters: 1488\n"]}]},{"cell_type":"code","source":["print(\"\\n--- HYBRID SUMMARY (gpt2-medium, strict & robust) ---\\n\")\n","summary = summarize_hybrid(text_data, bullets=4, max_sents=8)\n","print(summary)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7T6ziFvaUlv","executionInfo":{"status":"ok","timestamp":1757957374109,"user_tz":-180,"elapsed":58,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}},"outputId":"56d59cf6-3278-4772-a250-91dd003f6748"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- HYBRID SUMMARY (gpt2-medium, strict & robust) ---\n","\n","BULLETS:\n","- From healthcare to finance and transportation, AI systems are being used to analyze massive datasets, recognize complex patterns, and assist humans in making critical decisions.\n","- Breakthroughs in deep learning and natural language processing have led to impressive advances in image recognition, speech synthesis, and text generation.\n","- Modern AI faces three major challenges: explainability, efficiency, and security.\n","- Efficiency focuses on reducing computational costs through model compression, pruning, and quantization so that AI can run effectively even on limited hardware.\n","\n","PARAGRAPH:\n","From healthcare to finance and transportation, AI systems are being used to analyze massive datasets, recognize complex patterns, and assist humans in making critical decisions. Modern AI faces three major challenges: explainability, efficiency, and security. Efficiency focuses on reducing computational costs through model compression, pruning, and quantization so that AI can run effectively even on limited hardware. Security involves defending models against adversarial attacks, data poisoning, and distribution shifts that could degrade performance in real-world environments.\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Belgeler klasörünü oluştur (varsa zaten hata vermez)\n","os.makedirs(\"/content/drive/MyDrive/Belgeler\", exist_ok=True)\n","\n","# Kaydedilecek dosya yolu\n","out_path = \"/content/drive/MyDrive/Belgeler/summary.txt\"\n","\n","# Summary'yi yaz\n","with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","    f.write(summary)\n","\n","print(\"Saved:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SN-CtKrEcvbo","executionInfo":{"status":"ok","timestamp":1757957793267,"user_tz":-180,"elapsed":59,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}},"outputId":"1a5017af-61b5-493c-e42a-aeb657def242"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: /content/drive/MyDrive/Belgeler/summary.txt\n"]}]},{"cell_type":"code","source":["out_path = \"/content/drive/MyDrive/Belgeler/summary.txt\"\n","with open(out_path, \"w\", encoding=\"utf-8\") as f:\n","    f.write(summary)\n","print(\"Saved:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yo3N2Gi-czWg","executionInfo":{"status":"ok","timestamp":1757957826813,"user_tz":-180,"elapsed":55,"user":{"displayName":"Okyanus","userId":"07295594304534432579"}},"outputId":"df6231b9-21f3-442c-dcf6-a0612311f7cc"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: /content/drive/MyDrive/Belgeler/summary.txt\n"]}]}]}